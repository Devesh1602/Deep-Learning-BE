import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

fashion_mnist = tf.keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images.shape

train_images = train_images / 255.0
test_images = test_images / 255.0

# Verify data is in correct format
plt.figure(figsize = (10, 10))
for i in range(25):
  plt.subplot(5, 5, i + 1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(train_images[i], cmap = plt.cm.binary)
  plt.xlabel(class_names[train_labels[i]])
plt.show

from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape = (28, 28)),
    tf.keras.layers.Dense(128, activation = 'relu'),
    tf.keras.layers.Dense(10)
])

model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])
model.summary()

model.fit(train_images, train_labels, epochs = 10)

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose = 2)
print("\n Test accuracy = ", test_acc)

probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])

predictions = probability_model.predict(test_images)

def plot_image(i, predictions_array, true_label, img):
  true_label, img = true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

rows = 5
cols = 5
total_images = rows * cols
plt.figure(figsize = (2*2*cols, 2*rows))
for i in range(total_images):
  plt.subplot(rows, cols, i + 1)
  plot_image(i, predictions[i], test_labels, test_images)
plt.tight_layout()
plt.show()

=========================================Explanation===========================================
Importing the Dataset:
fashion_mnist = tf.keras.datasets.fashion_mnist
This line imports the Fashion MNIST dataset from TensorFlow's keras.datasets module. Fashion MNIST is a dataset of grayscale images of clothing items, consisting of 10 classes.

Loading the Data:
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

This line loads the dataset into four variables:
train_images: An array containing grayscale training images. Each image is represented as a 28x28 NumPy array with pixel values ranging from 0 to 255.
train_labels: An array containing the corresponding labels for the training images. Each label is an integer from 0 to 9, representing the class of the clothing item.
test_images: An array containing grayscale test images, similar to train_images.
test_labels: An array containing the corresponding labels for the test images, similar to train_labels.

The train_images.shape attribute provides information about the shape of the training images array in the Fashion MNIST dataset.

Normalization of Training Images:
train_images = train_images / 255.0

This line divides each pixel value in the train_images array by 255.0.
Since the pixel values range from 0 to 255 (grayscale), dividing by 255.0 scales these values to the range [0, 1].
Normalizing pixel values to this range is a common preprocessing step in deep learning, as it helps improve model convergence and stability during training.

Normalization of Test Images:
test_images = test_images / 255.0

Similar to the previous line, this line divides each pixel value in the test_images array by 255.0 to normalize the test images.

# Verify data is in correct format
plt.figure(figsize = (10, 10))
for i in range(25):
  plt.subplot(5, 5, i + 1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(train_images[i], cmap = plt.cm.binary)
  plt.xlabel(class_names[train_labels[i]])
plt.show

This loop iterates over the first 25 images in the training set.
For each iteration, it creates a subplot in a 5x5 grid using Matplotlib's plt.subplot() function.
plt.xticks([]) and plt.yticks([]) remove the tick marks on both the x-axis and y-axis.
plt.grid(False) turns off the grid lines.
plt.imshow(train_images[i], cmap=plt.cm.binary) displays the image represented by train_images[i] using a binary colormap (plt.cm.binary). This colormap is suitable for grayscale images.
plt.xlabel(class_names[train_labels[i]]) adds a label below each image indicating the corresponding class name (e.g., 'T-shirt/top', 'Trouser', etc.) based on the train_labels.

Displaying the Plot:
plt.show()
This line displays the plot containing the grid of images and labels.

Importing Necessary Modules:
from keras.models import Sequential
from keras.layers import Dense
These lines import the Sequential model and Dense layer classes from the Keras API. The Sequential model is used to create a linear stack of layers, 
while the Dense layer represents a fully connected layer in the neural network.

Defining the Sequential Model:
model = Sequential()
This line initializes a Sequential model, which allows you to build a neural network by adding layers sequentially.

Adding Layers to the Model:
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])
This code block defines the layers of the neural network and adds them to the Sequential model.
The Flatten layer flattens the input image from a 2D array (28x28 pixels) to a 1D array (784 pixels). It does not have any trainable parameters.
The first Dense layer consists of 128 neurons with ReLU activation function ('relu'). This layer is fully connected to the previous layer.
The second Dense layer consists of 10 neurons, corresponding to the number of classes in the Fashion MNIST dataset. It does not have an activation function specified,
which means it will output raw logits.

Compiling the Model:
model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
This line compiles the model using the specified optimizer, loss function, and metrics.
optimizer='adam': The Adam optimizer is chosen for optimization.
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True): Sparse categorical cross-entropy loss is used as the loss function. 
Since the model's output does not have a softmax activation applied, from_logits=True is set to ensure proper handling of logits.
metrics=['accuracy']: Accuracy is chosen as the evaluation metric to monitor during training.

Printing Model Summary:
model.summary()
This line prints a summary of the model's architecture, including the layers, output shape of each layer, and total number of parameters.

Training the Model:
model.fit(train_images, train_labels, epochs=10)
This line trains the model on the training data.
train_images and train_labels are the input images and corresponding labels from the Fashion MNIST training dataset.
epochs=10 specifies the number of training epochs, i.e., the number of times the model will iterate over the entire training dataset.

Model Evaluation:
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
This line evaluates the model on the test data (test_images and test_labels).
test_loss will contain the loss value computed during evaluation.
test_acc will contain the accuracy value computed during evaluation.
verbose=2 specifies the verbosity mode. Setting it to 2 displays a progress bar for each epoch during evaluation.

Printing Test Accuracy:
print("\nTest accuracy =", test_acc)
This line prints the test accuracy obtained from the evaluation.

Creating the Probability Model:
probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])
This line creates a new Sequential model (probability_model).
The Sequential model consists of the previously trained model (model) followed by a Softmax layer (tf.keras.layers.Softmax()).
The Softmax layer applies the softmax activation function to the logits output by the previous model, converting them into probabilities.

Making Predictions:
predictions = probability_model.predict(test_images)
This line uses the probability_model to make predictions on the test images (test_images).
The predict() method computes the output predictions for the given input data (images) using the trained model.

Function Definition:
def plot_image(i, predictions_array, true_label, img):
This line defines a function named plot_image that takes four parameters:
i: The index of the image to be plotted.
predictions_array: An array containing the predicted probabilities for each class.
true_label: The true label (ground truth) of the image.
img: The image data to be plotted.

Extracting True Label and Image:
true_label, img = true_label[i], img[i]
This line extracts the true label and image corresponding to the specified index i.

Plotting the Image:
plt.grid(False)
plt.xticks([])
plt.yticks([])
plt.imshow(img, cmap=plt.cm.binary)
These lines configure the plot settings: turning off the grid, ticks, and axis labels, and then displaying the image using Matplotlib's imshow() function.

Adding Predicted Label:
predicted_label = np.argmax(predictions_array)
if predicted_label == true_label:
    color = 'blue'
else:
    color = 'red'
This block determines the color (blue for correct prediction, red for incorrect prediction) based on whether the predicted label matches the true label.

Adding Label Information:
plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                              100*np.max(predictions_array),
                              class_names[true_label]),
                              color=color)
This line adds a label below the image indicating the predicted label, the confidence score (in percentage), and the true label.
The color of the label text is determined by the color variable.

Defining Rows and Columns for the Grid:
rows = 5
cols = 5
total_images = rows * cols
These lines define the number of rows (rows) and columns (cols) for the grid of images.
total_images calculates the total number of images to be plotted, which is the product of rows and cols.

Creating the Figure:
plt.figure(figsize=(2*2*cols, 2*rows))
This line creates a new figure with a specified size, where each subplot will be twice as wide and twice as tall as the default size.

Plotting Images in the Grid:
for i in range(total_images):
    plt.subplot(rows, cols, i + 1)
    plot_image(i, predictions[i], test_labels, test_images)
This loop iterates over each subplot in the grid.
For each iteration, it calls the plot_image function to plot the image at index i along with its predicted and true labels.

Adjusting Layout and Displaying the Plot:
plt.tight_layout()
plt.show()
plt.tight_layout() adjusts the spacing between subplots to prevent overlap.
plt.show() displays the plot containing the grid of images.


